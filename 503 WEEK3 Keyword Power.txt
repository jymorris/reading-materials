Hello, usually Johnny Cash comes along for these keyword videos. He couldn't be here today, but we're here with a keyword video anyway, today's keyword is power. The question of power runs throughout all of the weeks in this course, but it kind of remains in the background for most of the lectures or readings.
Play video starting at ::25 and follow transcript0:25
Understanding the concept of power is critical for any understanding of data science ethics, in their book data feminism. Catherine D'Ignazio and Lauren Klein give a definition of power as quote, the current configuration of structural privilege and structural oppression. In which some groups experience unearned advantages, because various systems have been designed by people like them, and work for people like them. And other groups experienced systematic disadvantages, because those same systems were not designed by them, or with people like them in mind. So you can see here that power helps us to understand how advantage and disadvantage, get embedded in systems through the ways that they are designed and implemented. This can be intentional or unintentional, and the systems can be social or technical in nature. But over time disparities become concretize and take the form of structural privilege and structural oppression, putting this in terms that might be familiar to you from SIADS 501. A key data science ethics question to always ask is, how does power operate in this system project or situation. In this class, we are suggesting that you can use power as an analytical lens. The calorie article emphasizes the idea that power is distributed unevenly across systems. And that asking questions about how power works in the system, fundamentally requires considering the larger context, that includes the various stakeholders involved, in the circumstances of system development or deployment. As calorie says, quote through the lens of power, it's possible to see why accurate generalize able and efficient. Ai systems are not good for everyone, in the hands of exploitative companies or oppressive law enforcement. A more accurate facial recognition system is harmful. Organizations have responded with pledges to design fair, and transparent systems, but fair and transparent according to whom, these systems sometimes mitigate harm, but are controlled by powerful institutions with their own agendas. At best, they're unreliable at worst. They masquerade as ethics watching technologies that still perpetuate inequity in an ethical analysis. It's not enough to think about a system in terms of positive steps, or negative harms. That's a start of course. But the key takeaway here, is that there are always differentials in experiencing outcomes or consequences, depending on who's involved. So, understanding how power works in a given situation helps us to understand how unfair or harmful systems perpetuate despite good intentions. So then you can use power as a kind of analytical tool to think with, questions about power relate to every step of a data science project from problem formulation, to reporting out results. Power is also relevant to data sets, and data subjects, who may include individuals, groups, projects, organizations, social or legal structures. Finally, you can also take a look at power with respect to almost any of the main topics of this course. Things like privacy, especially the issues around group privacy, or secondary use contexts for data, or bias and classification, provenance, accountability. So then the question, is how do you do this? How to investigate, how power operates in a given situation? We think that a good strategy, is to train yourself to ask some critical questions of the projects that you work on, or are asked to evaluate. It's more than just asking who has power, and who does not. It's fundamentally about asking who has the power to control outcomes through data science, and to explore the implications of the outcomes that are produced. So you could ask questions about stakeholders, by this I mean who has access in a project. Access to datasets to representation on project teams, or two high level decision making, and once you've mapped that out, you can begin to ask questions about what are the power differentials that are present among stakeholders. And then, we start to get at things like the power to set priorities, or the power to define or collect data, or the power to accept or refuse being a data subject. This analytical approach gives us a lot to work with when asking about how power imbalances can be challenged, and changed. I have an example for you, which I think is interesting because it illustrates how there are many different ways to consider power with respect to data driven projects, and systems. Power is at play in getting included in a system, or being excluded from a system, being a data subject willingly, or unwillingly. So if you think about the other weeks in this course, a lot of what we talk about with things like predictive policing, or risk assessment, or facial recognition systems, is about questions of power and surveillance. So for example, we might think about power and being a data subject. We can talk about data subjects lack of choice in opting in, or out of being included in these automated systems. But, there's a flip side to that. We can also talk about power with respect to exclusion, the risks that happen when people from dominant groups create most of our data products, is not only that data sets are biased, or unrepresentative, but also that they never get collected at all. Art can be useful in illustrating these concepts. This photo is from artist Mimi Wo Khas project called the library of missing data sets. It exists as a website and a series of installations, she created the project as a way of illustrating datasets that you would expect should exist, but don't. This would be in contrast to the many datasets that do exist, but probably should not. There are a series of labeled folders in a filing cabinet. The files, say things like number of Americans without bank accounts in 2008, or people excluded from public housing because of their criminal records. The files are empty for a reason, through some combination of personal, social, or political will, or lack there of these data sets don't exist. Therefore, programs can't be created that help to address the problems that the data sets would represent. Noah says that what we choose to ignore reveals as much or more, than what we choose to give our attention to. So the takeaway here, is that part of investigating how forces of power operate, is to critically question what data is collected, and what is not, or what it means to be included, or excluded from the data set, or how this gets decided. The reason this is important, is in part because as scholar Kate Crawford observes in this quote with respect to Ai, that it's quote invariably designed to amplify, and reproduce the forms of power. It has been deployed to optimize, countering now requires centering the interests of the communities most affected. She's talking here about Ai specifically, but I think it's pretty generalized able to data driven systems, especially those that automate decision making or seek to predict things. You could connect that to our framing questions related to bias and classification, is data signs backward looking. If it is, or if it's discriminatory like we discussed, this happens largely in service of maintaining the status quo, with respect to existing power structures. Crawford and others we've encountered in 503, argue that one way out of this, is to re center the voices and interests of communities that may be negatively impacted through these structural power operations. Or may have been excluded from being parts of the conversation around data science projects, or systems. So now we have the question of what does this mean for you? You might be concerned, that using power as an analytical lens is primarily a way to discover ethical problems, that does have some truth to it, but it's not where we're going to end here. Instead, I'd like to end with some additional suggestions from the authors of the book. Data feminism, where we got our definition of power from earlier. This is a list of things that data scientists might do to account for how power works in data science, and to integrate things like fairness, and accountability, and justice into your work. I think that this list does a nice job of bringing together some of the questions that I suggested to you earlier in this video. Or the critical lens that calorie brings in her article, or even the idea that it's important to include wide range of people, and perspectives in data science projects. I hope you can see from the list here, that when you start using power as an analytical lens, you can also find ways to reimagine, the design of a future for data science, that's more equitable, and just. Power asymmetries are often directly reflected in the power dynamics between who is doing the counting, and who is being counted. But when a community is counting for itself, about itself, there's potential that data collection can not only be empowering, but also healing.